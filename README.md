### papers reading

https://aclanthology.org/2021.bsnlp-1.2.pdf (russian, transformers is promising)

https://arxiv.org/pdf/2001.01941v1.pdf (generative process)

### dataset looking
https://www.kaggle.com/c/quora-question-pairs
https://github.com/google-research-datasets/paws

### model experimented
tf bilstm model (performed poorly)
transformer bert (much better than tf lstm)

### tools testing


### code